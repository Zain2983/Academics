{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7045374,
          "sourceType": "datasetVersion",
          "datasetId": 4054084
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install simpletransformers"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-11T15:54:43.837318Z",
          "iopub.execute_input": "2024-05-11T15:54:43.837666Z",
          "iopub.status.idle": "2024-05-11T15:55:02.696272Z",
          "shell.execute_reply.started": "2024-05-11T15:54:43.837639Z",
          "shell.execute_reply": "2024-05-11T15:55:02.695081Z"
        },
        "trusted": true,
        "id": "VBH6WuaDLsLH",
        "outputId": "21f02c37-cd41-4e91-c5c7-17d3b6a07d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting simpletransformers\n  Downloading simpletransformers-0.70.0-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.31.0)\nRequirement already satisfied: tqdm>=4.47.0 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (4.66.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2023.12.25)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (4.39.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.18.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.11.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.2.2)\nCollecting seqeval (from simpletransformers)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.15.1)\nRequirement already satisfied: tensorboardx in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.6.2.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.1.4)\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.15.2)\nRequirement already satisfied: wandb>=0.10.32 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.16.6)\nCollecting streamlit (from simpletransformers)\n  Downloading streamlit-1.34.0-py2.py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.22.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (6.0.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.4.3)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.41)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.20.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (2024.2.2)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets->simpletransformers) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.9.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2023.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (3.2.0)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.3.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.7.0)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.2.4)\nRequirement already satisfied: pillow<11,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (9.5.0)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (13.7.0)\nRequirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (8.2.3)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.9.0)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit->simpletransformers)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.3.3)\nCollecting watchdog>=2.1.5 (from streamlit->simpletransformers)\n  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl.metadata (37 kB)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.5.2)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.0.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (4.0.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.11)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->simpletransformers) (1.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->simpletransformers) (3.1.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.1)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.16.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.2)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->simpletransformers) (3.2.2)\nDownloading simpletransformers-0.70.0-py3-none-any.whl (315 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading streamlit-1.34.0-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=a1cc7288ca7e0a29fd6f7e139c3c4d2ca152c6c3bb061c2bfbfafef38ffd86a4\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: watchdog, pydeck, seqeval, streamlit, simpletransformers\nSuccessfully installed pydeck-0.9.1 seqeval-1.2.2 simpletransformers-0.70.0 streamlit-1.34.0 watchdog-4.0.0\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-11T15:55:13.108909Z",
          "iopub.execute_input": "2024-05-11T15:55:13.109267Z",
          "iopub.status.idle": "2024-05-11T15:55:25.100440Z",
          "shell.execute_reply.started": "2024-05-11T15:55:13.109240Z",
          "shell.execute_reply": "2024-05-11T15:55:25.099382Z"
        },
        "trusted": true,
        "id": "c1ldTzn1LsLI",
        "outputId": "3791d0a0-55d7-496e-c39d-acfb5abdbd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from simpletransformers.question_answering import QuestionAnsweringModel"
      ],
      "metadata": {
        "id": "1NuASbQqM8jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/kaggle/input/comprehensive-medical-q-a-dataset/train.csv\")\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
        "\n",
        "# Convert data to required format for Simple Transformers\n",
        "train_data = []\n",
        "for index, row in train_df.iterrows():\n",
        "    train_data.append({\"qas_id\": str(index), \"question\": row[\"Question\"], \"context\": row[\"Answer\"], \"answers\": {\"text\": [row[\"Answer\"]], \"answer_start\": [0]}})\n",
        "\n",
        "test_data = []\n",
        "for index, row in test_df.iterrows():\n",
        "    test_data.append({\"qas_id\": str(index), \"question\": row[\"Question\"], \"context\": row[\"Answer\"], \"answers\": {\"text\": [row[\"Answer\"]], \"answer_start\": [0]}})\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-11T16:06:53.892093Z",
          "iopub.execute_input": "2024-05-11T16:06:53.892457Z",
          "iopub.status.idle": "2024-05-11T16:06:55.158302Z",
          "shell.execute_reply.started": "2024-05-11T16:06:53.892426Z",
          "shell.execute_reply": "2024-05-11T16:06:55.157193Z"
        },
        "trusted": true,
        "id": "FCuhHHwjLsLJ",
        "outputId": "bb1d97bc-ec99-40fc-fd28-d7ea9f845d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "             qtype                                           Question  \\\n0   susceptibility  Who is at risk for Lymphocytic Choriomeningiti...   \n1         symptoms  What are the symptoms of Lymphocytic Choriomen...   \n2   susceptibility  Who is at risk for Lymphocytic Choriomeningiti...   \n3  exams and tests  How to diagnose Lymphocytic Choriomeningitis (...   \n4        treatment  What are the treatments for Lymphocytic Chorio...   \n\n                                              Answer  \n0  LCMV infections can occur after exposure to fr...  \n1  LCMV is most commonly recognized as causing ne...  \n2  Individuals of all ages who come into contact ...  \n3  During the first phase of the disease, the mos...  \n4  Aseptic meningitis, encephalitis, or meningoen...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qtype</th>\n      <th>Question</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>susceptibility</td>\n      <td>Who is at risk for Lymphocytic Choriomeningiti...</td>\n      <td>LCMV infections can occur after exposure to fr...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>symptoms</td>\n      <td>What are the symptoms of Lymphocytic Choriomen...</td>\n      <td>LCMV is most commonly recognized as causing ne...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>susceptibility</td>\n      <td>Who is at risk for Lymphocytic Choriomeningiti...</td>\n      <td>Individuals of all ages who come into contact ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>exams and tests</td>\n      <td>How to diagnose Lymphocytic Choriomeningitis (...</td>\n      <td>During the first phase of the disease, the mos...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>treatment</td>\n      <td>What are the treatments for Lymphocytic Chorio...</td>\n      <td>Aseptic meningitis, encephalitis, or meningoen...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "for index, row in train_df.iterrows():\n",
        "    train_data.append({\"context\": row[\"Answer\"], \"qas\": [{\"id\": str(index), \"question\": row[\"Question\"], \"answers\": [{\"text\": row[\"Answer\"], \"answer_start\": 0}]}]})\n",
        "\n",
        "test_data = []\n",
        "for index, row in test_df.iterrows():\n",
        "    test_data.append({\"context\": row[\"Answer\"], \"qas\": [{\"id\": str(index), \"question\": row[\"Question\"], \"answers\": [{\"text\": row[\"Answer\"], \"answer_start\": 0}]}]})\n",
        "\n",
        "\n",
        "train_data = train_data[0:5000]\n",
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-11T16:09:00.166359Z",
          "iopub.execute_input": "2024-05-11T16:09:00.166725Z",
          "iopub.status.idle": "2024-05-11T16:09:00.174401Z",
          "shell.execute_reply.started": "2024-05-11T16:09:00.166696Z",
          "shell.execute_reply": "2024-05-11T16:09:00.173129Z"
        },
        "trusted": true,
        "id": "KyvKKpQ1LsLK",
        "outputId": "3a2660e5-e22a-4d8c-cb2a-be4b70a4596e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "5000\n4102\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_args = {\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"max_seq_length\": 512,\n",
        "    \"num_train_epochs\": 3,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"learning_rate\": 3e-5,\n",
        "    \"doc_stride\": 128,\n",
        "    \"reprocess_input_data\": True,\n",
        "    \"evaluate_during_training\": True,\n",
        "    \"evaluate_during_training_steps\": 1000,\n",
        "    \"evaluate_during_training_verbose\": True,\n",
        "    \"use_cached_eval_features\": False,\n",
        "    \"save_eval_checkpoints\": False,\n",
        "    \"wandb_project\": \"medquad-bert\",\n",
        "    \"use_cuda\": True  # Set use_cuda to False\n",
        "}\n",
        "\n",
        "bert_model = QuestionAnsweringModel(\"bert\", \"bert-base-uncased\", args=bert_args)\n",
        "bert_model.train_model(train_data, eval_data=test_data)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-11T16:09:02.468261Z",
          "iopub.execute_input": "2024-05-11T16:09:02.468975Z",
          "iopub.status.idle": "2024-05-11T16:49:00.794408Z",
          "shell.execute_reply.started": "2024-05-11T16:09:02.468939Z",
          "shell.execute_reply": "2024-05-11T16:49:00.793453Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "82f2ceab06934f549111835576d95e81",
            "",
            "05cc3b68d13143399ca85add525feab0",
            "807fb3ce0a0e48be9b00b6b3b394993d",
            "888b464b342b4c0aa2c5757cccb096a7",
            "f5e6fced354646a5a4157673ae3d3ca9",
            "10ec61fbe18e4176a0ecc257c4026fef",
            "49391829d7714527b86d1de0e3ee6a70",
            "378041ad518340fba4f89be927f73ca9",
            "6d861e6055134b36aee229fc394c5bf5"
          ]
        },
        "id": "MHDAv5OQLsLK",
        "outputId": "f7639b2e-b318-4289-9167-779b777c481e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nconvert squad examples to features: 100%|██████████| 5000/5000 [01:06<00:00, 74.97it/s]\nadd example index and unique id: 100%|██████████| 5000/5000 [00:00<00:00, 496273.37it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82f2ceab06934f549111835576d95e81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Finishing last run (ID:u65d1wmt) before initializing another..."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▃▂▁▁</td></tr><tr><td>global_step</td><td>▁▃▅▆█</td></tr><tr><td>lr</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.01173</td></tr><tr><td>global_step</td><td>250</td></tr><tr><td>lr</td><td>2e-05</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">proud-jazz-1</strong> at: <a href='https://wandb.ai/fast232/medquad-bert/runs/u65d1wmt' target=\"_blank\">https://wandb.ai/fast232/medquad-bert/runs/u65d1wmt</a><br/> View project at: <a href='https://wandb.ai/fast232/medquad-bert' target=\"_blank\">https://wandb.ai/fast232/medquad-bert</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20240511_160419-u65d1wmt/logs</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Successfully finished last run (ID:u65d1wmt). Initializing new run:<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.16.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20240511_161034-uspnenea</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/fast232/medquad-bert/runs/uspnenea' target=\"_blank\">smooth-cosmos-2</a></strong> to <a href='https://wandb.ai/fast232/medquad-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/fast232/medquad-bert' target=\"_blank\">https://wandb.ai/fast232/medquad-bert</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/fast232/medquad-bert/runs/uspnenea' target=\"_blank\">https://wandb.ai/fast232/medquad-bert/runs/uspnenea</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Epoch 1 of 3:   0%|          | 0/870 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05cc3b68d13143399ca85add525feab0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nconvert squad examples to features:   0%|          | 0/4102 [00:00<?, ?it/s]\u001b[A\nconvert squad examples to features:   0%|          | 1/4102 [00:18<21:23:22, 18.78s/it]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:19<00:42, 72.40it/s]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:32<00:42, 72.40it/s]\u001b[A\nconvert squad examples to features:  50%|█████     | 2051/4102 [00:35<00:29, 68.41it/s]\u001b[A\nconvert squad examples to features: 100%|██████████| 4102/4102 [00:37<00:00, 110.21it/s]\u001b[A\n\nadd example index and unique id: 100%|██████████| 4102/4102 [00:00<00:00, 518974.27it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Evaluation:   0%|          | 0/56 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "807fb3ce0a0e48be9b00b6b3b394993d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Epoch 2 of 3:   0%|          | 0/870 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "888b464b342b4c0aa2c5757cccb096a7"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\n\nconvert squad examples to features:   0%|          | 0/4102 [00:00<?, ?it/s]\u001b[A\u001b[A\n\nconvert squad examples to features:   0%|          | 1/4102 [00:18<21:23:17, 18.78s/it]\u001b[A\u001b[A\n\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:19<00:41, 73.78it/s]\u001b[A\u001b[A\n\nconvert squad examples to features:  50%|█████     | 2051/4102 [00:35<00:29, 68.75it/s]\u001b[A\u001b[A\n\nconvert squad examples to features: 100%|██████████| 4102/4102 [00:37<00:00, 110.73it/s]\u001b[A\u001b[A\n\n\nadd example index and unique id: 100%|██████████| 4102/4102 [00:00<00:00, 504812.95it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Evaluation:   0%|          | 0/56 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5e6fced354646a5a4157673ae3d3ca9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nconvert squad examples to features:   0%|          | 0/4102 [00:00<?, ?it/s]\u001b[A\nconvert squad examples to features:   0%|          | 1/4102 [00:18<20:42:30, 18.18s/it]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:19<00:41, 74.66it/s]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:32<00:41, 74.66it/s]\u001b[A\nconvert squad examples to features:  50%|█████     | 2051/4102 [00:35<00:30, 67.41it/s]\u001b[A\nconvert squad examples to features: 100%|██████████| 4102/4102 [00:37<00:00, 109.85it/s]\u001b[A\n\nadd example index and unique id: 100%|██████████| 4102/4102 [00:00<00:00, 466868.42it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Evaluation:   0%|          | 0/56 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10ec61fbe18e4176a0ecc257c4026fef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Epoch 3 of 3:   0%|          | 0/870 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49391829d7714527b86d1de0e3ee6a70"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\n\nconvert squad examples to features:   0%|          | 0/4102 [00:00<?, ?it/s]\u001b[A\u001b[A\n\nconvert squad examples to features:   0%|          | 1/4102 [00:18<20:58:18, 18.41s/it]\u001b[A\u001b[A\n\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:19<00:41, 74.90it/s]\u001b[A\u001b[A\n\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:31<00:41, 74.90it/s]\u001b[A\u001b[A\n\nconvert squad examples to features:  50%|█████     | 2051/4102 [00:35<00:30, 67.09it/s]\u001b[A\u001b[A\n\nconvert squad examples to features: 100%|██████████| 4102/4102 [00:37<00:00, 109.62it/s]\u001b[A\u001b[A\n\n\nadd example index and unique id: 100%|██████████| 4102/4102 [00:00<00:00, 518317.62it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Evaluation:   0%|          | 0/56 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "378041ad518340fba4f89be927f73ca9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nconvert squad examples to features:   0%|          | 0/4102 [00:00<?, ?it/s]\u001b[A\nconvert squad examples to features:   0%|          | 1/4102 [00:18<21:02:23, 18.47s/it]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:19<00:42, 71.74it/s]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:31<00:42, 71.74it/s]\u001b[A\nconvert squad examples to features:  50%|█████     | 2051/4102 [00:35<00:30, 67.63it/s]\u001b[A\nconvert squad examples to features: 100%|██████████| 4102/4102 [00:37<00:00, 108.33it/s]\u001b[A\n\nadd example index and unique id: 100%|██████████| 4102/4102 [00:00<00:00, 511065.94it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Evaluation:   0%|          | 0/56 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d861e6055134b36aee229fc394c5bf5"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(2610,\n {'global_step': [870, 1000, 1740, 2000, 2610],\n  'correct': [818, 818, 818, 818, 818],\n  'similar': [2945, 2946, 2947, 2947, 2947],\n  'incorrect': [339, 338, 337, 337, 337],\n  'train_loss': [0.004629765171557665,\n   0.00105392187833786,\n   0.0002079265541397035,\n   0.0006839260458946228,\n   0.00012378182145766914],\n  'eval_loss': [-7.654994419642857,\n   -7.425013950892857,\n   -7.918038504464286,\n   -7.787388392857143,\n   -7.708426339285714]})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune MobileBERT\n",
        "mobilebert_args = {\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"max_seq_length\": 512,\n",
        "    \"num_train_epochs\": 3,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"learning_rate\": 3e-5,\n",
        "    \"doc_stride\": 128,\n",
        "    \"reprocess_input_data\": True,\n",
        "    \"evaluate_during_training\": True,\n",
        "    \"evaluate_during_training_steps\": 1000,\n",
        "    \"evaluate_during_training_verbose\": True,\n",
        "    \"use_cached_eval_features\": False,\n",
        "    \"save_eval_checkpoints\": False,\n",
        "    \"wandb_project\": \"medquad-mobilebert\",\n",
        "    \"use_cuda\": True\n",
        "}\n",
        "\n",
        "mobilebert_model = QuestionAnsweringModel(\"mobilebert\", \"google/mobilebert-uncased\", args=mobilebert_args)\n",
        "mobilebert_model.train_model(train_data, eval_data=test_data)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-11T16:58:35.580729Z",
          "iopub.execute_input": "2024-05-11T16:58:35.581150Z",
          "iopub.status.idle": "2024-05-11T17:27:48.591211Z",
          "shell.execute_reply.started": "2024-05-11T16:58:35.581111Z",
          "shell.execute_reply": "2024-05-11T17:27:48.590052Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "04bc9cec03764f2586f31279ce344f51",
            "8865fa12a0f24a7f8c50f007ddaf249e",
            "1f640391fa4e4c0c9eefcfac617d25f9",
            "8302f475660d41b7b7a409244685b1d4",
            "301fec0b3c344c2abbefcf85e763f315",
            "",
            "5399ff5f7cc447e09923caee43c5d41f",
            "d3de51c5bf1d41899cf380378dd3a1ab",
            "54b25cb2471c44f3b5327d8c5cd3ac5b",
            "542fc03ed9de4eeaa2f2afd0057f274e",
            "52ec34f931984eb889ea1513c1a0f5f5",
            "7de0b7b0c6ec4659b9e6cb9470cbddd9",
            "d3f0ed77af294c3c9de10f84e98f92dd",
            "a99281456c3d437889154afb7a762eb1"
          ]
        },
        "id": "QaG5rVTALsLK",
        "outputId": "da5ac2e6-8aa3-4a2f-dae9-b0eb468242a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/847 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04bc9cec03764f2586f31279ce344f51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/147M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8865fa12a0f24a7f8c50f007ddaf249e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of MobileBertForQuestionAnswering were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f640391fa4e4c0c9eefcfac617d25f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8302f475660d41b7b7a409244685b1d4"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "convert squad examples to features: 100%|██████████| 5000/5000 [01:05<00:00, 76.54it/s]\nadd example index and unique id: 100%|██████████| 5000/5000 [00:00<00:00, 495862.67it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "301fec0b3c344c2abbefcf85e763f315"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Finishing last run (ID:uspnenea) before initializing another..."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▁▂▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>correct</td><td>▁▁▁▁▁</td></tr><tr><td>eval_loss</td><td>▅█▁▃▄</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>incorrect</td><td>█▅▁▁▁</td></tr><tr><td>lr</td><td>▃▆████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>similar</td><td>▁▅███</td></tr><tr><td>train_loss</td><td>█▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.00013</td></tr><tr><td>correct</td><td>818</td></tr><tr><td>eval_loss</td><td>-7.70843</td></tr><tr><td>global_step</td><td>2610</td></tr><tr><td>incorrect</td><td>337</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>similar</td><td>2947</td></tr><tr><td>train_loss</td><td>0.00012</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">smooth-cosmos-2</strong> at: <a href='https://wandb.ai/fast232/medquad-bert/runs/uspnenea' target=\"_blank\">https://wandb.ai/fast232/medquad-bert/runs/uspnenea</a><br/> View project at: <a href='https://wandb.ai/fast232/medquad-bert' target=\"_blank\">https://wandb.ai/fast232/medquad-bert</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20240511_161034-uspnenea/logs</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Successfully finished last run (ID:uspnenea). Initializing new run:<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.16.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20240511_170009-fob8l1uo</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/fast232/medquad-mobilebert/runs/fob8l1uo' target=\"_blank\">exalted-cherry-1</a></strong> to <a href='https://wandb.ai/fast232/medquad-mobilebert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/fast232/medquad-mobilebert' target=\"_blank\">https://wandb.ai/fast232/medquad-mobilebert</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/fast232/medquad-mobilebert/runs/fob8l1uo' target=\"_blank\">https://wandb.ai/fast232/medquad-mobilebert/runs/fob8l1uo</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Epoch 1 of 3:   0%|          | 0/870 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5399ff5f7cc447e09923caee43c5d41f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nconvert squad examples to features:   0%|          | 0/4102 [00:00<?, ?it/s]\u001b[A\nconvert squad examples to features:   0%|          | 1/4102 [00:18<20:52:33, 18.33s/it]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:19<00:41, 73.84it/s]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:31<00:41, 73.84it/s]\u001b[A\nconvert squad examples to features:  50%|█████     | 2051/4102 [00:35<00:29, 68.52it/s]\u001b[A\nconvert squad examples to features: 100%|██████████| 4102/4102 [00:36<00:00, 111.51it/s]\u001b[A\n\nadd example index and unique id: 100%|██████████| 4102/4102 [00:00<00:00, 497931.73it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Evaluation:   0%|          | 0/56 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3de51c5bf1d41899cf380378dd3a1ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Epoch 2 of 3:   0%|          | 0/870 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54b25cb2471c44f3b5327d8c5cd3ac5b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\n\nconvert squad examples to features:   0%|          | 0/4102 [00:00<?, ?it/s]\u001b[A\u001b[A\n\nconvert squad examples to features:   0%|          | 1/4102 [00:19<22:34:47, 19.82s/it]\u001b[A\u001b[A\n\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:20<00:42, 71.73it/s]\u001b[A\u001b[A\n\nconvert squad examples to features:  50%|█████     | 2051/4102 [00:35<00:30, 67.81it/s]\u001b[A\u001b[A\n\nconvert squad examples to features: 100%|██████████| 4102/4102 [00:38<00:00, 107.82it/s]\u001b[A\u001b[A\n\n\nadd example index and unique id: 100%|██████████| 4102/4102 [00:00<00:00, 511689.12it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Evaluation:   0%|          | 0/56 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "542fc03ed9de4eeaa2f2afd0057f274e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nconvert squad examples to features:   0%|          | 0/4102 [00:00<?, ?it/s]\u001b[A\nconvert squad examples to features:   0%|          | 1/4102 [00:18<21:00:11, 18.44s/it]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:19<00:42, 72.67it/s]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:30<00:42, 72.67it/s]\u001b[A\nconvert squad examples to features:  50%|█████     | 2051/4102 [00:35<00:30, 66.48it/s]\u001b[A\nconvert squad examples to features: 100%|██████████| 4102/4102 [00:37<00:00, 109.19it/s]\u001b[A\n\nadd example index and unique id: 100%|██████████| 4102/4102 [00:00<00:00, 513154.23it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Evaluation:   0%|          | 0/56 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52ec34f931984eb889ea1513c1a0f5f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Epoch 3 of 3:   0%|          | 0/870 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7de0b7b0c6ec4659b9e6cb9470cbddd9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\n\nconvert squad examples to features:   0%|          | 0/4102 [00:00<?, ?it/s]\u001b[A\u001b[A\n\nconvert squad examples to features:   0%|          | 1/4102 [00:18<21:04:55, 18.51s/it]\u001b[A\u001b[A\n\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:19<00:42, 73.22it/s]\u001b[A\u001b[A\n\nconvert squad examples to features:  50%|█████     | 2051/4102 [00:34<00:29, 69.40it/s]\u001b[A\u001b[A\n\nconvert squad examples to features: 100%|██████████| 4102/4102 [00:36<00:00, 111.08it/s]\u001b[A\u001b[A\n\n\nadd example index and unique id: 100%|██████████| 4102/4102 [00:00<00:00, 516869.50it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Evaluation:   0%|          | 0/56 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3f0ed77af294c3c9de10f84e98f92dd"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nconvert squad examples to features:   0%|          | 0/4102 [00:00<?, ?it/s]\u001b[A\nconvert squad examples to features:   0%|          | 1/4102 [00:18<20:49:26, 18.28s/it]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:19<00:42, 72.39it/s]\u001b[A\nconvert squad examples to features:  25%|██▌       | 1026/4102 [00:34<00:42, 72.39it/s]\u001b[A\nconvert squad examples to features:  50%|█████     | 2051/4102 [00:34<00:29, 69.55it/s]\u001b[A\nconvert squad examples to features: 100%|██████████| 4102/4102 [00:36<00:00, 111.07it/s]\u001b[A\n\nadd example index and unique id: 100%|██████████| 4102/4102 [00:00<00:00, 514289.32it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Evaluation:   0%|          | 0/56 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a99281456c3d437889154afb7a762eb1"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(2610,\n {'global_step': [870, 1000, 1740, 2000, 2610],\n  'correct': [0, 0, 0, 0, 0],\n  'similar': [4102, 4102, 4102, 4102, 4102],\n  'incorrect': [0, 0, 0, 0, 0],\n  'train_loss': [nan, nan, nan, nan, nan],\n  'eval_loss': [nan, nan, nan, nan, nan]})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune RoBERTa\n",
        "roberta_args = {\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"max_seq_length\": 512,\n",
        "    \"num_train_epochs\": 3,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"learning_rate\": 3e-5,\n",
        "    \"doc_stride\": 128,\n",
        "    \"reprocess_input_data\": True,\n",
        "    \"evaluate_during_training\": True,\n",
        "    \"evaluate_during_training_steps\": 1000,\n",
        "    \"evaluate_during_training_verbose\": True,\n",
        "    \"use_cached_eval_features\": False,\n",
        "    \"save_eval_checkpoints\": False,\n",
        "    \"wandb_project\": \"medquad-roberta\",\n",
        "    \"use_cuda\": True\n",
        "}\n",
        "\n",
        "roberta_model = QuestionAnsweringModel(\"roberta\", \"roberta-base\", args=roberta_args)\n",
        "roberta_model.train_model(train_data, eval_data=test_data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-11T17:37:04.047281Z",
          "iopub.execute_input": "2024-05-11T17:37:04.048012Z",
          "iopub.status.idle": "2024-05-11T17:38:55.368143Z",
          "shell.execute_reply.started": "2024-05-11T17:37:04.047959Z",
          "shell.execute_reply": "2024-05-11T17:38:55.366351Z"
        },
        "trusted": true,
        "id": "dNb4YANSLsLK",
        "outputId": "56fc4be8-8502-45aa-8d43-8b6b42eedcf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nconvert squad examples to features:   0%|          | 0/5000 [01:44<?, ?it/s]Process ForkPoolWorker-30:\nProcess ForkPoolWorker-29:\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/data/processors/squad.py\", line 147, in squad_convert_example_to_features\n    (tok_start_position, tok_end_position) = _improve_answer_span(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/data/processors/squad.py\", line 147, in squad_convert_example_to_features\n    (tok_start_position, tok_end_position) = _improve_answer_span(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/data/processors/squad.py\", line 49, in _improve_answer_span\n    text_span = \" \".join(doc_tokens[new_start : (new_end + 1)])\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/data/processors/squad.py\", line 49, in _improve_answer_span\n    text_span = \" \".join(doc_tokens[new_start : (new_end + 1)])\nKeyboardInterrupt\nKeyboardInterrupt\n\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 20\u001b[0m\n\u001b[1;32m      2\u001b[0m roberta_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_output_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_seq_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cuda\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m roberta_model \u001b[38;5;241m=\u001b[39m QuestionAnsweringModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m=\u001b[39mroberta_args)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mroberta_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/simpletransformers/question_answering/question_answering_model.py:448\u001b[0m, in \u001b[0;36mQuestionAnsweringModel.train_model\u001b[0;34m(self, train_data, output_dir, show_running_loss, args, eval_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         train_examples \u001b[38;5;241m=\u001b[39m train_data\n\u001b[0;32m--> 448\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_and_cache_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    452\u001b[0m global_step, training_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m    453\u001b[0m     train_dataset,\n\u001b[1;32m    454\u001b[0m     output_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    458\u001b[0m )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/simpletransformers/question_answering/question_answering_model.py:355\u001b[0m, in \u001b[0;36mQuestionAnsweringModel.load_and_cache_examples\u001b[0;34m(self, examples, evaluate, no_cache, output_examples)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Converting to features started.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 355\u001b[0m     features, dataset \u001b[38;5;241m=\u001b[39m \u001b[43msquad_convert_examples_to_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdoc_stride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_stride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_query_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_query_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_cache:\n\u001b[1;32m    368\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(features, cached_features_file)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/simpletransformers/question_answering/question_answering_utils.py:480\u001b[0m, in \u001b[0;36msquad_convert_examples_to_features\u001b[0;34m(examples, tokenizer, max_seq_length, doc_stride, max_query_length, is_training, padding_strategy, return_dataset, threads, tqdm_enabled, args)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(\n\u001b[1;32m    468\u001b[0m         threads,\n\u001b[1;32m    469\u001b[0m         initializer\u001b[38;5;241m=\u001b[39msquad_convert_example_to_features_init,\n\u001b[1;32m    470\u001b[0m         initargs\u001b[38;5;241m=\u001b[39m(tokenizer,),\n\u001b[1;32m    471\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m    472\u001b[0m         annotate_ \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    473\u001b[0m             squad_convert_example_to_features,\n\u001b[1;32m    474\u001b[0m             max_seq_length\u001b[38;5;241m=\u001b[39mmax_seq_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    478\u001b[0m             is_training\u001b[38;5;241m=\u001b[39mis_training,\n\u001b[1;32m    479\u001b[0m         )\n\u001b[0;32m--> 480\u001b[0m         features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m                \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotate_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconvert squad examples to features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     squad_convert_example_to_features_init(tokenizer)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:423\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    415\u001b[0m result \u001b[38;5;241m=\u001b[39m IMapIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_taskqueue\u001b[38;5;241m.\u001b[39mput(\n\u001b[1;32m    417\u001b[0m     (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_guarded_task_generation(result\u001b[38;5;241m.\u001b[39m_job,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m         result\u001b[38;5;241m.\u001b[39m_set_length\n\u001b[1;32m    422\u001b[0m     ))\n\u001b[0;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (item \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m chunk)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result, texts = bert_model.eval_model(test_data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-11T17:39:24.979152Z",
          "iopub.execute_input": "2024-05-11T17:39:24.980195Z",
          "iopub.status.idle": "2024-05-11T17:43:13.248313Z",
          "shell.execute_reply.started": "2024-05-11T17:39:24.980142Z",
          "shell.execute_reply": "2024-05-11T17:43:13.247281Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "af3a4c13071a43589474491253e24f2d"
          ]
        },
        "id": "m7v-jCNQLsLK",
        "outputId": "564cef58-918b-4d8c-e95a-3849c05959e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "convert squad examples to features: 100%|██████████| 4102/4102 [00:38<00:00, 105.26it/s]\nadd example index and unique id: 100%|██████████| 4102/4102 [00:00<00:00, 493023.33it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running Evaluation:   0%|          | 0/56 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af3a4c13071a43589474491253e24f2d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper Tunning\n",
        "# Define hyperparameters to tune\n",
        "hyperparameters = {\n",
        "    \"dropout_rate\": [0.3, 0.5, 0.7],\n",
        "    \"num_hidden_layers\": [6, 8, 12],\n",
        "    \"learning_rate\": [1e-5, 2e-5, 3e-5]\n",
        "}\n",
        "\n",
        "best_f1_score = 0\n",
        "best_hyperparameters = None\n",
        "\n",
        "# Loop through all combinations of hyperparameters\n",
        "for dropout_rate in hyperparameters[\"dropout_rate\"]:\n",
        "    for num_hidden_layers in hyperparameters[\"num_hidden_layers\"]:\n",
        "        for learning_rate in hyperparameters[\"learning_rate\"]:\n",
        "            # Define model with current hyperparameters\n",
        "            model_args = {\n",
        "                \"dropout_rate\": dropout_rate,\n",
        "                \"num_hidden_layers\": num_hidden_layers,\n",
        "                \"learning_rate\": learning_rate,\n",
        "            }\n",
        "\n",
        "            # Fine-tune model with current hyperparameters\n",
        "            model = QuestionAnsweringModel(\"bert\", \"bert-base-uncased\", args=model_args)\n",
        "            model.train_model(train_data, eval_data=test_data)\n",
        "\n",
        "            result, _ = model.eval_model(test_data)\n",
        "            f1_score = result[\"f1\"]\n",
        "\n",
        "            if f1_score > best_f1_score:\n",
        "                best_f1_score = f1_score\n",
        "                best_hyperparameters = model_args\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
        "print(\"Best F1 Score:\", best_f1_score)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-11T17:44:51.771299Z",
          "iopub.execute_input": "2024-05-11T17:44:51.771964Z",
          "iopub.status.idle": "2024-05-11T17:44:52.312136Z",
          "shell.execute_reply.started": "2024-05-11T17:44:51.771931Z",
          "shell.execute_reply": "2024-05-11T17:44:52.310645Z"
        },
        "trusted": true,
        "id": "pb6uQfHaLsLK",
        "outputId": "2e0bcf72-4499-4169-8395-3ac644111ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Fine-tune model with current hyperparameters\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m QuestionAnsweringModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m=\u001b[39mmodel_args)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval_model(test_data)\n\u001b[1;32m     28\u001b[0m f1_score \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/simpletransformers/question_answering/question_answering_model.py:421\u001b[0m, in \u001b[0;36mQuestionAnsweringModel.train_model\u001b[0;34m(self, train_data, output_dir, show_running_loss, args, eval_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moutput_dir\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    417\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_dir)\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(output_dir)\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moverwrite_output_dir\n\u001b[1;32m    420\u001b[0m ):\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput directory (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) already exists and is not empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse --overwrite_output_dir to overcome.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(output_dir)\n\u001b[1;32m    424\u001b[0m     )\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_model_to_device()\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_hf_datasets:\n",
            "\u001b[0;31mValueError\u001b[0m: Output directory (outputs/) already exists and is not empty.Use --overwrite_output_dir to overcome."
          ],
          "ename": "ValueError",
          "evalue": "Output directory (outputs/) already exists and is not empty.Use --overwrite_output_dir to overcome.",
          "output_type": "error"
        }
      ]
    }
  ]
}